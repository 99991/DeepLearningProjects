1)
code be coded
insert network.pdf here
why did we choose this?
TODO

2)
comments be made
reduce loss defined by softmax_cross_entropy_with_logits
tried: MomentumOptimizer, GradientDescentOptimizer
AdamOptimizer converged faster and to higher accuracy

3)
plots be plotted

4)
not at gpu (threads end different all times)
cpu same, if seed is set
mnist loader randomizes batches
can be seeded with np.random.seed(seed)
dropout layer and truncated_normal weight initialization have seed parameter

5)
runtimes in data, most (very good) runs about 3 minutes

6)
learning_rate.pdf
super high learning rate: does not learn at all (not on plot)
very small learning rate: takes forever to converge
high learning rate: maximum accuracy not reached

7)
see figures
99_43.pdf

8)
see plots

9)
kleinste Konfiguration => 97,4%
('num_hidden', 64)
('num_kernels1', 4)
('learning_rate', 0.001)
('regularization_factor', 0.0001)
('batch_size', 2048)
('dropout_keep_probability', 0.25)
('seed', 666)
('kernel1_size', 3)
('test_interval', 100)
('num_batches', 20001)
('pool', 4)

kleine Konfiguration => 99%
('num_hidden', 512)
('num_kernels1', 16)
('learning_rate', 0.001)
('regularization_factor', 0.0001)
('batch_size', 512)
('dropout_keep_probability', 0.25)
('seed', 666)
('kernel1_size', 5)
('test_interval', 100)
('num_batches', 2001)
('pool', 4)

10)
Pooling < 4 actually decreases accuracy while increasing runtime
Pooling > 4 decreases accuracy while decreasing runtime
